{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3dc88220",
   "metadata": {},
   "source": [
    "This is a first draft of code for the INT2 project. Most variables have been chosen quite arbitrarily - I have signified where this is the case, so that we know what to experiment with in order to improve the code.\n",
    "\n",
    "*Note you need to have pytorch installed already*\n",
    "\n",
    "First, we load and transform the CIFAR10 dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "785ac824",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "our_transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "\n",
    "# first we load the data into a training set and a testing set\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=our_transform)\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=our_transform)\n",
    "\n",
    "# now we create loader objects that allow us to iterate through the data\n",
    "trainloader = DataLoader(trainset, batch_size=8, shuffle=True, num_workers=2)\n",
    "testloader = DataLoader(testset, batch_size=8, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d92a1ebf",
   "metadata": {},
   "source": [
    "The definition of our_transform is not my own, here's an explanation of what it's supposed to do:\n",
    "\n",
    "'toTesnor()' converts the image data into a tensor format (necessary to work with easily)\n",
    "\n",
    "'Normalize()' normalises the tensor data (i.e. setting x = x_mean / standard_deviation). The triples (0.5, 0.5, 0.5) are apparently supposed to represent the means and standard deviations respectively for each of the three RGB channels (red/green/blue). Why they should all be set to 0.5 isn't very clear to me.\n",
    "\n",
    "As for the loaders, the choice 'batch_size=4' and 'num_workers=2' is completely arbitrary - although I originally ran it with batch_size=8 and got much worse results, so maybe 4 is a good choice? Batch size seems to be to do with the amount of data that is held in memory at any one time, though I don't really understand it, and 'num_workers' is about the number of threads that can run concurrently.\n",
    "\n",
    "We will now set up the neural network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e67a3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        # defines the layers\n",
    "        self.conv1 = nn.Conv2d(3, 16, 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 64, 3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.linear1 = nn.Linear(64*8*8, 512)\n",
    "        self.linear2 = nn.Linear(512, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 64*8*8) # reshaping the output from the second convolutional layer\n",
    "        x = F.relu(self.linear1(x))\n",
    "        x = self.linear2(x)\n",
    "        return x\n",
    "\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "237dd16b",
   "metadata": {},
   "source": [
    "This network has two convolutional layers (which extract low-level features), two pooling layers (to extract more information from the convolutional layer), and two linear layers (which do the actual linear classifying). More layers, especially more convolutional layers, might be a good idea.\n",
    "\n",
    "The numbers in each layer are again arbitrarily chosen - for the most part. In 'conv1', the first 3 represents the 3 input channels (that is, the 3 RGB channels), and the last 3 denotes kernel size, i.e. the convolution is done with a 3x3 filter. Apparently it is good to keep the kernel size at either 3 or 5 (why, I have no idea).\n",
    "It is important that the 16 - which represents number of output channels - in conv1 matches the 16 in the first place of conv2, as the output from conv1 is also the input to conv2 (technically there is a pooling step in between but this doesn't change the number of channels). Similarly if a third layer was added the input dimension would have to be 64 (unless we changed the output dimension of conv2)\n",
    "The optional variable padding='1' ensures the convolutional layers do not change the output dimension.\n",
    "\n",
    "If you get an error 'expected input size to match target size' when running the training part below (as I did), add a line 'print(x.shape)' just before the line starting 'x = x.view('. This will output an array - multiply all but the first number together and set that as the input dimension for the first linear layer. If you don't do this it forces the batch size to change: https://discuss.pytorch.org/t/valueerror-expected-input-batch-size-324-to-match-target-batch-size-4/24498/4\n",
    "\n",
    "In linear2, the output dimension of 10 is important - this is the number of categories we are trying to classify into.\n",
    "\n",
    "Now we define the loss function and optimizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "477dc486",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01, momentum = 0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246d9179",
   "metadata": {},
   "source": [
    "CrossEntropyLoss is apparently a relatively (computationally) simple loss function which suits our purposes okay.\n",
    "There are a few optional parameters for 'optim.SGD' which might be worth playing around with, check the documentation here: https://pytorch.org/docs/master/generated/torch.optim.SGD.html\n",
    "\n",
    "Now we train the network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ac3dd5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run  1  complete\n",
      "Run  2  complete\n",
      "Run  3  complete\n",
      "Run  4  complete\n",
      "All done\n"
     ]
    }
   ],
   "source": [
    "# run for 4 Epochs, i.e. loop over the dataset 4 times\n",
    "for epoch in range(1, 5):\n",
    "    train_loss, valid_loss = [], []\n",
    "    \n",
    "    # training \n",
    "    net.train()\n",
    "    for data, target in trainloader:\n",
    "        optimizer.zero_grad()\n",
    "        output = net(data)\n",
    "        loss = loss_function(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss.append(loss.item()) \n",
    "    \n",
    "    print('Run ', epoch, ' complete') # track progress\n",
    "print('All done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e384cef",
   "metadata": {},
   "source": [
    "The above took a little over 15 minutes to run on my computer (though for some reason it was only using about 60% of the CPU, maybe this is something to do with the batch_size=4 or the num_workers=2 from earlier?)\n",
    "\n",
    "Running for more epochs would probably help, but I suspect altering the definition of the NN would help more. *Edit: I've ran it twice - once w\n",
    "\n",
    "Now we can test the model, first by just seeing how it performs on a single batch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf393a06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted:    cat  ship  ship plane\n",
      "Actual:    cat  ship  ship plane\n"
     ]
    }
   ],
   "source": [
    "test_iterator = iter(testloader)\n",
    "data, labels = test_iterator.next()\n",
    "output = net(data)\n",
    "\n",
    "_, predicted = torch.max(output, 1)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "print('Predicted: ', ' '.join('%5s' % classes[predicted[j]]\n",
    "                              for j in range(4)))\n",
    "print('Actual: ', ' '.join('%5s' % classes[labels[j]]\n",
    "                              for j in range(4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c8382a9",
   "metadata": {},
   "source": [
    "And now over the whole dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0faa86da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 58 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "285e0e48",
   "metadata": {},
   "source": [
    "And finally on each individual category:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aaa04743",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of plane : 58 %\n",
      "Accuracy of   car : 73 %\n",
      "Accuracy of  bird : 38 %\n",
      "Accuracy of   cat : 47 %\n",
      "Accuracy of  deer : 52 %\n",
      "Accuracy of   dog : 53 %\n",
      "Accuracy of  frog : 56 %\n",
      "Accuracy of horse : 68 %\n",
      "Accuracy of  ship : 82 %\n",
      "Accuracy of truck : 59 %\n"
     ]
    }
   ],
   "source": [
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(4):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    print('Accuracy of %5s : %2d %%' % (\n",
    "        classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "344a6668",
   "metadata": {},
   "source": [
    "Do be aware that none of the testing code above is originally mine, but rather is taken from the wiki I linked to on github.\n",
    "\n",
    "**Final observations**\n",
    "- I haven't used CUDA to run this on GPU instead of CPU.\n",
    "- Here's a useful guide on figuring out sizes for NN layers: https://towardsdatascience.com/pytorch-layer-dimensions-what-sizes-should-they-be-and-why-4265a41e01fd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4deb5cd0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
